{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u29zbdsK59Ln"
   },
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5703: Machine Learning Practice__\n",
    "\n",
    "# Homework 8: Support Vector Machines\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code.  \n",
    "Post any questions regarding the assignment, to Slack.\n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring support vector machines (SVMs)\n",
    "using GridsearchCV and working with highly a unbalanced datasets.\n",
    "\n",
    "\n",
    "### [Data set](https://www.kaggle.com/kerneler/starter-credit-card-fraud-detection-e6d0de2d-9)\n",
    "European Cardholder Credit Card Transactions, September 2013  \n",
    "This dataset presents transactions that occurred over two days. There were 377 incidents of \n",
    "fraud out of 191,828 transactions. The dataset is highly unbalanced, the positive class \n",
    "(frauds) accounts for 0.197% of all transactions.\n",
    "\n",
    "__Features__  \n",
    "* V1, V2, ... V28: are principal components obtained with PCA from a large feature vector\n",
    "* Time: the seconds elapsed between each transaction and the first transaction  \n",
    "* Amount: is the transaction Amount  \n",
    "* Class: the predicted variable; 1 in case of fraud and 0 otherwise.  \n",
    "\n",
    "Given the class imbalance, it is recommended to use precision, recall and the \n",
    "Area Under the Precision-Recall Curve (AUPRC) to evaluate skill. Traditional accuracy \n",
    "and AUC are not meaningful for highly unbalanced classification, as these scores are \n",
    "misleading due to the high impact of the large number of negative cases that can easily\n",
    "be identified. \n",
    "\n",
    "Examining precision and recall is more informative as these disregard the number of \n",
    "correctly identified negative cases (i.e. TN) and focus on the number of correctly \n",
    "identified positive cases (TP) and mis-identified negative cases (FP). Another useful \n",
    "metric is the F1 score which is the harmonic mean of the precision and recall; 1 is the \n",
    "best F1 score.\n",
    "\n",
    "Confusion Matrix  \n",
    "[TN  FP]  \n",
    "[FN  TP]\n",
    "\n",
    "Accuracy = $\\frac{TN + TP}{TN + TP + FN + FP}$  \n",
    "TPR = $\\frac{TP}{TP + FN}$  \n",
    "FPR = $\\frac{FP}{FP + TN}$  \n",
    "\n",
    "Recall = TPR = $\\frac{TP}{TP + FN}$  \n",
    "Precision = $\\frac{TP}{TP + FP}$  \n",
    "F1 Score = 2 * $\\frac{precision \\; \\times \\; recall}{precision \\; + \\; recall}$  \n",
    "\n",
    "See the references below for more details on precision, recall, and the F1 score.\n",
    "\n",
    "\n",
    "The dataset was collected and analysed during a research collaboration of \n",
    "Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Universit√© \n",
    "Libre de Bruxelles) on big data mining and fraud detection [1]\n",
    "\n",
    "[1] Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi.\n",
    "Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium\n",
    "on Computational Intelligence and Data Mining (CIDM), IEEE, 2015.\n",
    "http://mlg.ulb.ac.be/BruFence . http://mlg.ulb.ac.be/ARTML\n",
    "\n",
    "\n",
    "### Objectives\n",
    "* Understanding Support Vector Machines\n",
    "* GridSearch with Classification\n",
    "* Creating Scoring functions\n",
    "* Stratification\n",
    "\n",
    "### Notes\n",
    "* Save your work in your own Google Drive or on your own computer\n",
    "* Note that there are three supporting python files that must be placed in the same folder as your notebook\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Scoring Parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "* [Scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring)\n",
    "* [Plot ROC](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)\n",
    "* [Precision, Recall, F1 Score](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "* [Precision-Recall Curve](https://acutecaretesting.org/en/articles/precision-recall-curves-what-are-they-and-how-are-they-used)\n",
    "* [Probability Plot](https://www.itl.nist.gov/div898/handbook/eda/section3/normprpl.htm)\n",
    "\n",
    "### Hand-In Procedure\n",
    "* Execute all cells so they are showing correct results\n",
    "* Notebook (from Jupyter or Colab):\n",
    "  + Submit this file (.ipynb) to the Gradescope Notebook HW8 dropbox\n",
    "* Note: there is no need to submit a PDF file or to submit directly to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSD3ADUB59Lt"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn\n",
    "import scipy.stats as stats\n",
    "import os, re, fnmatch\n",
    "import pathlib, itertools\n",
    "import time as timelib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import floor, ceil\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "\n",
    "#HOME_DIR = pathlib.Path.home()\n",
    "#CW_DIR = pathlib.Path.cwd()\n",
    "\n",
    "# Default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (6,5)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd1IYzdc59Lv",
    "outputId": "43d7b637-8875-42d5-9e76-30c783ccc342"
   },
   "outputs": [],
   "source": [
    "# COLAB ONLY\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd1IYzdc59Lv",
    "outputId": "43d7b637-8875-42d5-9e76-30c783ccc342"
   },
   "outputs": [],
   "source": [
    "# TODO: COLAB ONLY\n",
    "# THIS IMPORTS 3 CUSTOM .py FILES \n",
    "# You must seperately download these files and store them in the \n",
    "# Colab Notebooks folder\n",
    "# If you are running this on a local machine, then do not execute\n",
    "# this cell (execute the one below)\n",
    "\n",
    "# this is a little weird colab doesn't play _super_ nice with local \n",
    "# python files\n",
    "# note that this is not programming best practice\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/visualize.py', 'r'\n",
    ").read())\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/metrics_plots.py', 'r'\n",
    ").read())\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/pipeline_components.py', 'r'\n",
    ").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd1IYzdc59Lv",
    "outputId": "43d7b637-8875-42d5-9e76-30c783ccc342"
   },
   "outputs": [],
   "source": [
    "# for local runtimes only: DO NOT EXECUTE IN COLAB\n",
    "from visualize import *\n",
    "from metrics_plots import *\n",
    "from pipeline_components import DataSampleDropper, DataFrameSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-QkBYso59Lx"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWBhV3Sc59Ly",
    "outputId": "890a4372-308f-49d8-927a-5147bee8a825"
   },
   "outputs": [],
   "source": [
    "# 'None' to read whole file\n",
    "nRowsRead = None \n",
    "\n",
    "# TODO: set appropriately\n",
    "filename = '/content/drive/MyDrive/MLP_2022/datasets/creditcard.csv'\n",
    "#filename = 'creditcard.csv'\n",
    "\n",
    "# Read the CSV file and extract the table\n",
    "crime_stats_full = pd.read_csv(filename, delimiter=',', nrows=nRowsRead)\n",
    "crime_stats_full.dataframeName = 'creditcard.csv'\n",
    "nRows, nCols = crime_stats_full.shape\n",
    "print(f'There are {nRows} rows and {nCols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGBQBZ5759Lz",
    "outputId": "ae215455-a0c3-4e0b-e5f2-0f3ef1620381"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "good (negative case = 0)\n",
    "fraud (positive case = 1)\n",
    "\"\"\"\n",
    "targetnames = ['good', 'fraud']\n",
    "\n",
    "neg_full = crime_stats_full.loc[crime_stats_full['Class'] == 0] \n",
    "pos_full = crime_stats_full.loc[crime_stats_full['Class'] == 1] \n",
    "\n",
    "pos_full.shape, neg_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxdXId0B59L1",
    "outputId": "0b637d59-adce-45f4-e2c3-5d3314679400"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compute the postive and negative fractions\n",
    "\"\"\"\n",
    "pos_fraction = pos_full.shape[0] / nRows\n",
    "neg_fraction = 1 - pos_fraction\n",
    "\n",
    "pos_fraction, neg_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_HubIaj59L2",
    "outputId": "bdcfb223-5688-4565-fc0a-9f4b22f9ed84"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Select Random Subset of data\n",
    "\"\"\"\n",
    "np.random.seed(1138)\n",
    "subset_size = 50000\n",
    "selected_indices = np.random.choice(range(nRows), size=subset_size, replace=False)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4SgxJSI59L4",
    "outputId": "f5316edc-c12c-4124-e89c-db9a85a51e3c"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "List the features and shape of the data\n",
    "\"\"\"\n",
    "crime_stats = crime_stats_full.loc[selected_indices,:]\n",
    "crime_stats.columns, crime_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "8hKszl4w59L5",
    "outputId": "bc3f90c9-b6da-4687-fa02-280afccab4dc"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display summary statistics for each feature of the dataframe\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "8hKszl4w59L5",
    "outputId": "bc3f90c9-b6da-4687-fa02-280afccab4dc"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display whether there are any NaNs\n",
    "\"\"\"\n",
    "crime_stats.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itS10Ie759L6"
   },
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FWp-_zSo59L6",
    "outputId": "79a3ac73-1079-4a73-9367-151e7a67e897",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the distributions of the data\n",
    "use visualize.featureplots(...)\n",
    "to generate trace plots, histograms, boxplots, and probability plots for\n",
    "each feature.\n",
    "\n",
    "A probability plot is used to evaulate the normality of a distribution.\n",
    "The data are plotted against a theoritical distribution, such that if the data \n",
    "are normal, they'll follow the diagonal line. See the reference above for \n",
    "more information.\n",
    "\"\"\"\n",
    "\n",
    "crime_stats_clean = crime_stats.dropna()\n",
    "\n",
    "# TODO: visualize the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "YhhoKcjd59L7",
    "outputId": "7ab4e965-0d0d-4776-c9f4-e0b4559e2912"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the Pearson correlation between all pairs of the features\n",
    "\"\"\"\n",
    "scatter_corrplots(crime_stats_clean.values, crime_stats_clean.columns, corrfmt=\"%.1f\", FIGW=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKsM67LZ59L7",
    "outputId": "59d5f16f-bd31-4995-9593-9b04a1eee5d8"
   },
   "source": [
    "## TODO Reflection #1\n",
    "\n",
    "1. Which features correlate the most with the Amount feature?\n",
    "\n",
    "**TODO**\n",
    "\n",
    "2. Which features correlate the most with the class label?\n",
    "\n",
    "**TODO**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKsM67LZ59L7",
    "outputId": "59d5f16f-bd31-4995-9593-9b04a1eee5d8"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Separate the postive and negative examples\n",
    "\"\"\"\n",
    "neg = crime_stats.loc[crime_stats['Class'] == 0] \n",
    "pos = crime_stats.loc[crime_stats['Class'] == 1] \n",
    "\n",
    "pos.shape, neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K77YQfSh59L8",
    "outputId": "f92621be-ef10-4a95-ef20-991a12ac6dbb"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compute the postive and negative fractions\n",
    "\"\"\"\n",
    "pos_fraction = pos.shape[0] / (pos.shape[0] + neg.shape[0])\n",
    "neg_fraction = 1 - pos_fraction\n",
    "\n",
    "pos_fraction, neg_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "Ucxwr9mO59L9",
    "outputId": "913e5a8d-0c9a-4d15-8be7-58db41eccf31"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Compare the features for the positive and negative examples\n",
    "\"\"\"\n",
    "features_displayed = pos.columns\n",
    "ndisplayed = len(features_displayed)\n",
    "ncols = 5\n",
    "nrows = ceil(ndisplayed/ncols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for ax, feat_name in zip(axs, features_displayed):\n",
    "    bp = np.array([neg[feat_name], pos[feat_name]], copy=False, dtype=object)\n",
    "    boxplot = ax.boxplot(bp, patch_artist=True, sym='.')\n",
    "    boxplot['boxes'][0].set_facecolor('pink')\n",
    "    boxplot['boxes'][1].set_facecolor('lightblue')\n",
    "    ax.set_xticklabels(['-', '+'])\n",
    "    ax.set(title=feat_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaajiyVc59L-"
   },
   "source": [
    "## TODO Reflection #2\n",
    "\n",
    "1. Which features show a different mean value across the positive and negative classes?\n",
    "\n",
    "**TODO**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaajiyVc59L-"
   },
   "source": [
    "# PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EpL4L9t59L-"
   },
   "source": [
    "## Data Clean Up and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JaXSdCf59L-"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Construct Pipeline to pre-process data\n",
    "\"\"\"\n",
    "feature_names = crime_stats.columns.drop(['Class'])\n",
    "pipe_X = Pipeline([\n",
    "    (\"NaNrowDropper\", DataSampleDropper()),\n",
    "    (\"selectAttribs\", DataFrameSelector(feature_names)),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "pipe_y = Pipeline([\n",
    "    (\"NaNrowDropper\", DataSampleDropper()),\n",
    "    (\"selectAttribs\", DataFrameSelector(['Class']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a62qEWYp59L_",
    "outputId": "b0b996f0-0a3b-4820-a0db-7702951e557c"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Pre-process the data using the pipeliine\n",
    "\n",
    "NOTE: generally, we should only fit these pipelines to the training/validation data and NOT\n",
    "the test data.  However, we will take this shortcut here.\n",
    "\"\"\"\n",
    "X = #TODO\n",
    "y = #TODO\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KznzxfMX59L_",
    "outputId": "dd0c8539-cb9c-4ee2-c00d-1d1d5c10dfcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Re-visualize the pre-processed data\n",
    "use visualize.featureplots()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yDaSA4w59MA"
   },
   "source": [
    "# SVMs: EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZkrtNmJ59MB"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Hold out a subset of the data, before training and cross validation\n",
    "using train_test_split, with stratify NOT equal to None, and a test_size \n",
    "fraction of .2.\n",
    "\n",
    "For this exploratory section, the held out set of data is a validation set.\n",
    "For the GridSearch section, the held out set of data is a test set.  Again, this is for\n",
    "convenience here.  But, generally, a test set should always be treated as a test set.\n",
    "\n",
    "Note that train_test_split() from scikit-learn does not use the data set names properly\n",
    "\n",
    "\"\"\"\n",
    "Xtrain, Xval, ytrain, yval = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isnKZIoD59MB",
    "outputId": "61eefd9e-0b45-4645-c126-c64588733616"
   },
   "outputs": [],
   "source": [
    "yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZk1P4zB59MB",
    "outputId": "01aca6ab-4ede-476b-d18b-e33863d937c4"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create and train SVC models. \n",
    "Explore various configurations of the hyper-parameters. \n",
    "Train the models on the training set and evaluate them for the training and\n",
    "validation sets.\n",
    "\n",
    "Try different choices for C, gamma, and class_weight. Feel free to play with other hyper-\n",
    "parameters as well. See the API for more details.\n",
    "C is a regularization parameter, gamma is the inverse of the radius of influence\n",
    "of the support vectors (i.e. lower gamma means a higher radius of influence of the \n",
    "support vectors), and class weight determines whether to adjust the weights inversely\n",
    "to the class fractions.\n",
    "\"\"\"\n",
    "model = #TODO\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyttrW_-59MC"
   },
   "source": [
    "### Train Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "gkL_v2QQ59MC",
    "outputId": "cd617ed0-c17e-48e6-de97-4543c2dcde99"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Evaluate training set performance. \n",
    "Display the confusion matrix, KS plot with\n",
    "the cumulative distributions of the TPR and FPR, the ROC curve and the \n",
    "precision-recall curve (PRC). \n",
    "\n",
    "The PRC, unlike the AUC, does not consider the true negative (i.e. TN) counts,\n",
    "making the PRC more sensitive to unbalanced datasets.\n",
    "\"\"\"\n",
    "# TODO: Compute the predictions for the training set\n",
    "preds = #TODO\n",
    "\n",
    "# TODO: Compute the confusion matrix\n",
    "confusion_mtx = #TODO\n",
    "\n",
    "# TODO: Plot the confusion matrix in graphical form (see metrics_plots)\n",
    "#TODO\n",
    "\n",
    "# TODO: Use the model's predict_proba function to compute the probabilities\n",
    "#  We will use only the fraud case probabilities for our analysis.  Select these\n",
    "probas = #TODO\n",
    "\n",
    "# TODO: display the KS plot, ROC, and PRC (see metrics_plots)\n",
    "roc_prc_results = #TODO\n",
    "\n",
    "# Compute performance scores\n",
    "pss_train = skillScore(ytrain, preds)\n",
    "f1_train = f1_score(ytrain.ravel(), preds)\n",
    "print(\"PSS: %.4f\" % pss_train[0])\n",
    "print(\"F1 Score %.4f\" % f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Utv4r2EE59ME"
   },
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "J_E0t5uP59ME",
    "outputId": "a01e2eb4-0a1d-4c7f-9d4f-2430e69c29bb"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Evaluate validation performance. \n",
    "Display the confusion matrix, KS plot with the cumulative distributions of the TPR \n",
    "and FPR, the ROC curve and the precision-recall curve (PRC).\n",
    "\"\"\"\n",
    "# TODO: Confusion matrix\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "\n",
    "# Report scores\n",
    "pss_val = skillScore(yval, preds_val)\n",
    "f1_val = f1_score(yval, preds_val)\n",
    "print(\"PSS: %.4f\" % pss_val[0])\n",
    "print(\"F1 Score %.4f\" % f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QbmbvZO59ME"
   },
   "source": [
    "## TODO Reflection #3\n",
    "1. Compare / contrast the training and validation set results\n",
    "\n",
    "**TODO**\n",
    "\n",
    "2. Which metric is most sensitive to the overfitting?\n",
    "\n",
    "**TODO**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QbmbvZO59ME"
   },
   "source": [
    "# SVMs: STRATIFIED GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHTPpp3_59MF"
   },
   "source": [
    "## Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duafVwtk59MF",
    "outputId": "d10d9886-19a7-4c8a-e979-cd8f50200f9e"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "List of available scoring functions from the sklearn module\n",
    "\"\"\"\n",
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdcdQyBL59MG"
   },
   "source": [
    "## Execute Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXdatuGE59MG",
    "outputId": "9e878424-ac2f-4870-b19c-7a60ea60863a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Estimated time: ~2 hrs on CoLab\n",
    "Set up and run a grid search using GridSearchCV and the following \n",
    "settings:\n",
    "* SVC for the model,\n",
    "* The given scoring dictionary for scoring,\n",
    "* refit set to opt_metric\n",
    "* Five for the number of cv folds, \n",
    "* n_jobs=-1,\n",
    "* verbose=2, \n",
    "* return_train_score=True\n",
    "\"\"\"\n",
    "# Optimized metric\n",
    "opt_metric = 'f1'\n",
    "scoring = {opt_metric:opt_metric}\n",
    "\n",
    "# Flag to force re-execution of the learning process\n",
    "force = False\n",
    "\n",
    "# File name containing results from previous run \n",
    "\n",
    "#srchfname = \"/content/drive/My Drive/Colab Notebooks/hw8_search_\" + opt_metric + \".pkl\"\n",
    "srchfname = \"hw8_search_\" + opt_metric + \".pkl\"\n",
    "\n",
    "\n",
    "# SETUP EXPERIMENT HYPERPARAMETERS\n",
    "Cs = np.logspace(-1, 2, num=5, endpoint=True, base=10)\n",
    "gammas = np.logspace(-5, 0, num=5, endpoint=True, base=5)\n",
    "\n",
    "# Number of each parameter type\n",
    "nCs = len(Cs)\n",
    "ngammas = len(gammas)\n",
    "\n",
    "# Create th hyperparameter specification\n",
    "hyperparams = {'C':Cs, 'gamma':gammas, 'tol':[1e-4],\n",
    "               'class_weight':[None, 'balanced'], \n",
    "               'probability':[True]}\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "time0 = timelib.time()\n",
    "search = None\n",
    "if force or (not os.path.exists(srchfname)):\n",
    "    # TODO: Create the GridSearchCV object\n",
    "    search = #TODO\n",
    "    \n",
    "    # TODO: Execute the grid search by calling fit using the training data\n",
    "       \n",
    "    \n",
    "    # Save the grid search object\n",
    "    joblib.dump(search, srchfname)\n",
    "    print(\"Saved %s\" % srchfname)\n",
    "else:\n",
    "    search = joblib.load(srchfname)\n",
    "    print(\"Loaded %s\" % srchfname)\n",
    "\n",
    "time1 = timelib.time()\n",
    "duration = time1 - time0\n",
    "print(\"Elapsed Time: %.2f min\" % (duration / 60))\n",
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR_5ljOq59MG"
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "ycGR8PtP59MG",
    "outputId": "945ebca9-c469-4b9d-f37f-53eb8773601a"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the results for the grid search\n",
    "See the cv_results_ attribute\n",
    "\"\"\"\n",
    "all_results = search.cv_results_\n",
    "df_res = pd.DataFrame(all_results)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "88fWkRvt59MG",
    "outputId": "a325439f-c6a5-4919-82c5-7329629f240a"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot the mean training and validation results from the grid search as a\n",
    "colormap, for C (y-axis) vs the gamma (x-axis), for class_weight=None\n",
    "\"\"\"\n",
    "results_grid_train = df_res['mean_train_'+opt_metric].values.reshape(nCs, 2, ngammas)\n",
    "results_grid_val = df_res['mean_test_'+opt_metric].values.reshape(nCs, 2, ngammas)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6,6))\n",
    "axs = axs.ravel()\n",
    "means = [(\"Training\", results_grid_train),\n",
    "         (\"Validation\", results_grid_val)]\n",
    "for i, (name, result) in enumerate(means):\n",
    "    img = axs[i].imshow(result[:,0,:], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xticks(range(ngammas))\n",
    "    axs[i].set_yticks(range(nCs))\n",
    "    axs[i].set_xticklabels(np.around(gammas, 3))\n",
    "    axs[i].set_yticklabels(np.around(Cs, 3))\n",
    "    axs[i].figure.colorbar(img, ax=axs[i], label=opt_metric, \n",
    "                           orientation='horizontal')\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel(\"C\")\n",
    "    axs[i].set_xlabel(r\"$\\gamma$\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "s6FBq6K_59MG",
    "outputId": "7f02b4fb-cf88-420f-9202-7b6fe03a4547"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Plot the mean training and validation results from the grid search as a\n",
    "colormap, for C (y-axis) vs the gamma (x-axis), for class_weight='balanced'\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6,6))\n",
    "axs = axs.ravel()\n",
    "means = [(\"Training\", results_grid_train),\n",
    "         (\"Validation\", results_grid_val)]\n",
    "for i, (name, result) in enumerate(means):\n",
    "    img = axs[i].imshow(result[:,1,:], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xticks(range(ngammas))\n",
    "    axs[i].set_yticks(range(nCs))\n",
    "    axs[i].set_xticklabels(np.around(gammas, 3))\n",
    "    axs[i].set_yticklabels(np.around(Cs, 3))\n",
    "    axs[i].figure.colorbar(img, ax=axs[i], label=opt_metric, \n",
    "                           orientation='horizontal')\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel(\"C\")\n",
    "    axs[i].set_xlabel(r\"$\\gamma$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyDz3_bg59MH",
    "outputId": "87a65668-7692-47db-d536-3b7bf403e7f0"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Obtain the best model from the grid search and \n",
    "fit it to the full training data\n",
    "\"\"\"\n",
    "best_model = search.best_estimator_\n",
    "best_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TAvs3Za59MH"
   },
   "source": [
    "### Train Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "ZMid7Di159MI",
    "outputId": "240b59cd-a835-4d49-ef63-b56e953a23f2"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "For the best model, display the confusion matrix, KS plot, ROC curve, \n",
    "and PR curve for the training set\n",
    "\"\"\"\n",
    "# TODO: Confusion Matrix\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "# Report results\n",
    "pss_res = skillScore(ytrain, preds)\n",
    "f1_res = f1_score(ytrain, preds)\n",
    "print(\"PSS: %.4f\" % pss_res[0])\n",
    "print(\"F1 Score %.4f\" % f1_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDOPi_Nl59MI"
   },
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "zuq5g70M59MI",
    "outputId": "7ba3012e-c1c7-46c8-845a-3bdfad26b9f6"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "For the best model, display the confusion matrix, KS plot, ROC curve, \n",
    "and PR curve for the validation set\n",
    "\"\"\"\n",
    "# TODO: Confustion Matrix\n",
    "\n",
    "# TODO: Curves\n",
    "\n",
    "# Report results\n",
    "pss_res_val = skillScore(yval, preds_val)\n",
    "f1_res_val = f1_score(yval, preds_val)\n",
    "print(\"PSS: %.4f\" % pss_res_val[0])\n",
    "print(\"F1 Score %.4f\" % f1_res_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCZ9se-h59MK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWQ6aXLY59MK"
   },
   "source": [
    "## TODO Reflection #4\n",
    "Discuss and interpret the validation results for the best model. \n",
    "\n",
    "**TODO**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEI8Srx659ML"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rkopgYm59MM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework8-sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
