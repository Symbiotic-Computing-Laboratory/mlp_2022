{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhPKRulBifpn"
   },
   "source": [
    "__NAME:__ __FULLNAME__  \n",
    "__SECTION:__ __NUMBER__  \n",
    "__CS 5703: Machine Learning Practices__\n",
    "\n",
    "# Homework 9: Decision Tree Classifiers\n",
    "\n",
    "## Assignment Overview\n",
    "Follow the TODOs and read through and understand any provided code. \n",
    "Post any questions you might have to the class Slack. \n",
    "For all plots, make sure all necessary axes and curves are clearly and \n",
    "accurately labeled. Include figure/plot titles appropriately as well.\n",
    "\n",
    "\n",
    "### Task\n",
    "For this assignment you will be exploring Decision Tree Classifiers to \n",
    "predict potentially fraudulent providers from summary statistics of their filed healthcare claims. \n",
    "\n",
    "These data were re-configured from a dataset collected for the purpose of detecting Health care Provider Fraud. Total Medicare spending increases exponentially due to fraud in Medicare claims. Healthcare fraud involves health care providers, physicians, patients, and beneficiaries acting in tandum to construct fraudulent claims.\n",
    "\n",
    "\n",
    "__Features__  \n",
    "The features are aggregate statistics computed as either the mean or the sum.\n",
    "For the following features, the column represents the average value for the provider's claims:  \n",
    "* InscClaimAmtReimbursed  \n",
    "* DeductibleAmtPaid\n",
    "* NoOfMonths_PartACov\n",
    "* NoOfMonths_PartBCov\n",
    "* IPAnnualReimbursementAmt\n",
    "* IPAnnualDeductibleAmt\n",
    "* OPAnnualReimbursementAmt\n",
    "* OPAnnualDeductibleAmt\n",
    "* NumPhysiciansSeen\n",
    "* NumProcedures\n",
    "* NumDiagnosisClaims\n",
    "* Age\n",
    " \n",
    "For the following features, the column represents the total number among the provider's claims:  \n",
    "* ChronicCond_Alzheimer  \n",
    "* ChronicCond_Heartfailure  \n",
    "* ChronicCond_KidneyDisease  \n",
    "* ChronicCond_Cancer  \n",
    "* ChronicCond_ObstrPulmonary  \n",
    "* ChronicCond_Depression  \n",
    "* ChronicCond_Diabetes  \n",
    "* ChronicCond_IschemicHeart  \n",
    "* ChronicCond_Osteoporasis  \n",
    "* ChronicCond_rheumatoidarthritis  \n",
    "* ChronicCond_stroke  \n",
    "* RenalDiseaseIndicator  \n",
    "\n",
    "These data were amalagmated from the [HEALTHCARE PROVIDER FRAUD DETECTION ANALYSIS](https://www.kaggle.com/rohitrox/healthcare-provider-fraud-detection-analysis) data set on Kaggle.\n",
    "\n",
    "\n",
    "### Objectives\n",
    "* Introduction to Decision Trees\n",
    "\n",
    "\n",
    "### General References\n",
    "* [Guide to Jupyter](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Numpy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [DataCamp: Matplotlib](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=1565261270&utm_adgroupid=67750485268&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332661264365&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=9026223&gclid=CjwKCAjw_uDsBRAMEiwAaFiHa8xhgCsO9wVcuZPGjAyVGTitb_-fxYtkBLkQ4E_GjSCZFVCqYCGkphoCjucQAvD_BwE)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* [Sci-kit Learn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [Sci-kit Learn Preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)  \n",
    "* [Decision Trees](https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567)\n",
    "\n",
    "### Hand-In Procedure\n",
    "* Execute all cells so they are showing correct results\n",
    "* Notebook (from Jupyter or Colab):\n",
    "  + Submit this file (.ipynb) to the Gradescope Notebook HW9 dropbox\n",
    "* Note: there is no need to submit a PDF file or to submit directly to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOj7opaqifpx"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, os, pathlib\n",
    "import time as timelib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import log_loss, f1_score, precision_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "import joblib\n",
    "import pickle as pkl\n",
    "\n",
    "# Default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (6,5)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['figure.constrained_layout.use'] = False\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxurFy_oifp0"
   },
   "outputs": [],
   "source": [
    "# COLAB ONLY\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RzdhtbsjY3K"
   },
   "outputs": [],
   "source": [
    "# COLAB ONLY\n",
    "#\n",
    "# THIS IMPORTS 3 CUSTOM .py FILES \n",
    "# \n",
    "# These are the same python files as we used in HW08\n",
    "#\n",
    "# If you are running this on a local machine, don't execute this cell\n",
    "#\n",
    "\n",
    "# this is a little weird colab doesn't play _super_ nice with local \n",
    "# python files\n",
    "# note that this is not programming best practice\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/visualize.py', 'r'\n",
    ").read())\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/metrics_plots.py', 'r'\n",
    ").read())\n",
    "exec(open(\n",
    "    '/content/drive/My Drive/Colab Notebooks/pipeline_components.py', 'r'\n",
    ").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RzdhtbsjY3K"
   },
   "outputs": [],
   "source": [
    "# for local runtimes only (e.g., Jupyter)\n",
    "from visualize import *\n",
    "from metrics_plots import *\n",
    "from pipeline_components import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8HZRjjPifp3"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thtXl0VXifp4"
   },
   "outputs": [],
   "source": [
    "# TODO: set path appropriately. \n",
    "fname = \"/content/drive/My Drive/MLP_2021/datasets/health_provider_fraud.csv\"\n",
    "#fname = \"health_provider_fraud.csv\"\n",
    "claims_data = pd.read_csv(fname)\n",
    "claims_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS7PI0yEifp5"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display data info\n",
    "\"\"\"\n",
    "claims_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRkYCI29ifp6"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the data\n",
    "\"\"\"\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gs7Lt8zaifp8"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the summary statistics\n",
    "Make sure you skim this\n",
    "\"\"\"\n",
    "claims_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOu-VAGZifp9"
   },
   "source": [
    "# PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX8uj0kEifp9"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Construct preprocessing pipeline\n",
    "\"\"\"\n",
    "selected_features = claims_data.columns.drop(['Provider'])\n",
    "scaled_features = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid',\n",
    "                   'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
    "                   'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('RowDropper', DataSampleDropper()),\n",
    "    ('FeatureSelector', DataFrameSelector(selected_features)),\n",
    "    ('Scale', DataScaler(scaled_features))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vqk2XJMZifp_"
   },
   "outputs": [],
   "source": [
    "\"\"\" Provided: execute cell\n",
    "Pre-process the data using the defined pipeline\n",
    "\"\"\"\n",
    "processed_data = pipe.fit_transform(claims_data)\n",
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2srzXxKHifqA"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED: execute cell\n",
    "Verify all NaNs removed\n",
    "\"\"\"\n",
    "processed_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8QxkogXifqB"
   },
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbosiY6GifqB"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot the class distributions for no potential fraud and potential fraud\n",
    "\"\"\"\n",
    "class_counts = pd.value_counts(processed_data['PotentialFraud'])\n",
    "class_counts.plot(kind='bar', rot=0, figsize=(10,3))\n",
    "plt.title(\"Potential Cases of Fraud\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Display the class fractions\n",
    "nsamples, nfeatures = processed_data.shape\n",
    "class_counts / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzLq2E8xifqC"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Extract indices of the postive and negative cases\n",
    "\"\"\"\n",
    "pos = processed_data['PotentialFraud'] == 1\n",
    "neg = processed_data['PotentialFraud'] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92mbX0aXifqD"
   },
   "source": [
    "# Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTDY7ZqJifqE"
   },
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWLNhiufifqE"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Split data into X (the inputs) and y (the outputs)\n",
    "\n",
    "Hold out a subset of the data, before training and cross validation\n",
    "using train_test_split, with stratify equal to something other than NONE, \n",
    "and a test_size fraction of .2.\n",
    "\n",
    "For this exploratory section, the held out set of data is a validation set.\n",
    "For the GridSearch section, the held out set of data is a test set.\n",
    "\"\"\"\n",
    "targetnames = ['NonFraud', 'Fraud']\n",
    "\n",
    "# Create the inputs and outputs\n",
    "X = processed_data.drop(['PotentialFraud'], axis=1).copy()\n",
    "y = processed_data['PotentialFraud'].values.ravel()\n",
    "\n",
    "# Split data into train and test sets\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, stratify=y, random_state=1138, test_size=0.5)\n",
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDuy_ZR1ifqF"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Explore interesting hyper-parameters. Train multiple decision trees using the training set only.\n",
    "Pick your favorite model to leave within your submitted report.\n",
    "\"\"\"\n",
    "# TODO: Create and fit the model\n",
    "tree_model = DecisionTreeClassifier(???)\n",
    "tree_model.fit(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBzfrC8RifqG"
   },
   "outputs": [],
   "source": [
    "# PROVIDED: Predict with the model on the validation set\n",
    "preds_val = tree_model.predict(Xval)\n",
    "\n",
    "# Obtain prediction probabilities for the test set, using \n",
    "proba_val = tree_model.predict_proba(Xval)  \n",
    "\n",
    "# Obtain the classifier accuracy score for the test set using the\n",
    "scores = tree_model.score(Xval, yval)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvvQmGYZifqG"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the confusion matrix, KS plot, ROC curve, and PR curve for the validation set\n",
    "using metrics_plots.ks_roc_prc_plot\n",
    "\n",
    "The red dashed line in the PRC is indicative of the expected performance for a random\n",
    "classifier, which would predict postives at the rate of occurance within the data set\n",
    "\"\"\"\n",
    "# Confusion Matrix\n",
    "cmtx_val = confusion_matrix(yval, preds_val)\n",
    "confusion_mtx_colormap(cmtx_val, targetnames, targetnames)\n",
    "\n",
    "# Curves\n",
    "# Note, you'll want the probability class predictions for the class label 1\n",
    "# See the API page for the DecisionTreeClassifier predict_proba; proba_val[:,1]\n",
    "roc_prc_results_val  = ks_roc_prc_plot(yval, proba_val[:,1])\n",
    "\n",
    "# Obtain the PSS and F1 Score\n",
    "pss_val = skillScore(yval, preds_val)\n",
    "\n",
    "# pss_val = metrics_plots.skillScore(ytest, preds_val)\n",
    "f1_val = f1_score(yval, preds_val)\n",
    "print(\"PSS: %.4f\" % pss_val[0])\n",
    "print(\"F1 Score %.4f\" % f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnTlKj1UifqH"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Export the image of the tree model\n",
    "\"\"\"\n",
    "from IPython.display import Image\n",
    "export_graphviz(tree_model, out_file='exploratory_model.dot', \n",
    "                feature_names=X.columns, class_names=targetnames, \n",
    "                rounded=True, filled=True)\n",
    "!dot -Tpng exploratory_model.dot > e_model.png\n",
    "Image(filename='e_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xKecVj6ifqH"
   },
   "source": [
    "# GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s16MZfkdifqI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(arr):\n",
    "    ''' \n",
    "    Remove duplicates from an array\n",
    "    '''\n",
    "    out = []\n",
    "    for i in arr:\n",
    "        if not i in out:\n",
    "            out.append(i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s16MZfkdifqI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Set up and run the grid search using GridSearchCV and the following \n",
    "settings:\n",
    "* The below scoring dictionary for scoring\n",
    "* refit set to 'f1' as the optimized metric\n",
    "* Choose a range of regularization types and parameters\n",
    "\"\"\"\n",
    "# Optimized metric\n",
    "opt_metric = 'f1'\n",
    "scoring = {opt_metric:opt_metric}\n",
    "\n",
    "# Flag to re-load previous run regardless of whether the file exists\n",
    "#force = False\n",
    "force = True\n",
    "\n",
    "# File previous run is saved to\n",
    "srchfname = \"/content/drive/My Drive/Colab Notebooks/hw9_search_sol_\" + opt_metric + \".pkl\"\n",
    "#srchfname = \"hw9_search_sol_\" + opt_metric + \".pkl\"\n",
    "\n",
    "\n",
    "# SETUP EXPERIMENT HYPERPARAMETERS\n",
    "# TODO\n",
    "\n",
    "# TODO: Create the dictionary of hyper-parameters to try\n",
    "hyperparams = {# TODO}\n",
    "\n",
    "\n",
    "# RUN EXPERIMENT\n",
    "time0 = timelib.time()\n",
    "search = None\n",
    "if force or (not os.path.exists(srchfname)):\n",
    "    # Create the GridSearchCV object\n",
    "    base_model = DecisionTreeClassifier()\n",
    "    search = GridSearchCV(base_model, hyperparams, scoring=scoring, refit=opt_metric,\n",
    "                          cv=40, n_jobs=-1, verbose=2, return_train_score=True)\n",
    "    \n",
    "    # TODO: Execute the grid search by calling fit using the training data\n",
    "    search.fit(???)\n",
    "    \n",
    "    # Save the grid search object\n",
    "    joblib.dump(search, srchfname)\n",
    "    print(\"Saved %s\" % srchfname)\n",
    "else:\n",
    "    # TODO: Re-load the grid search object\n",
    "    search = joblib.load(srchfname)\n",
    "    print(\"Loaded %s\" % srchfname)\n",
    "\n",
    "time1 = timelib.time()\n",
    "duration = time1 - time0\n",
    "print(\"Elapsed Time: %.2f min\" % (duration / 60))\n",
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F90T0UDifqJ"
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRpcar-UifqJ"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Display the head of the results for the grid search\n",
    "See the cv_results_ attribute\n",
    "\"\"\"\n",
    "all_results = search.cv_results_\n",
    "df_res = pd.DataFrame(all_results)\n",
    "df_res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixAssol_ifqK"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDE\n",
    "Obtain the best model from the grid search and \n",
    "fit it to the full training data\n",
    "\"\"\"\n",
    "best_model = search.best_estimator_\n",
    "best_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXzT1Q68ifqK"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Export the image of the best model\n",
    "use export_graphviz\n",
    "\"\"\"\n",
    "export_graphviz(best_model, out_file='best_model.dot', \n",
    "                feature_names=X.columns, class_names=targetnames,\n",
    "                rounded=True, filled=True)\n",
    "!dot -Tpng best_model.dot > b_model.png\n",
    "Image(filename='b_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNUsBIz_ifqL"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Plot a histogram of the val scores from the best model.\n",
    "Compare the distribution of probabilities for positive and negative examples\n",
    "using boxplots.\n",
    "\n",
    "Create one subplot of the distribution of all the probabilities, with a histogram. \n",
    "Create a second subplot comparing the distribution of the scores of the \n",
    "positive examples with the distribution of the negative examples, with boxplots.\n",
    "\"\"\"\n",
    "# Obtain the pos and neg indices\n",
    "pos_inds = yval == 1\n",
    "neg_inds = yval == 0\n",
    "\n",
    "# Obtain prediction probabilities for the test set (use model.predict_proba)\n",
    "proba_val = best_model.predict_proba(Xval)\n",
    "\n",
    "# Separate the probabilities for the pos and neg examples\n",
    "proba_pos = proba_val[pos_inds, 1]\n",
    "proba_neg = proba_val[neg_inds, 1]\n",
    "\n",
    "# Plot the distribution of all probabilities\n",
    "nbins = 21\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(proba_val[:,1], bins=nbins)\n",
    "plt.xlabel('probability')\n",
    "plt.ylabel('count')\n",
    "plt.title(\"Distribution of Instance Probabilities\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(proba_neg, bins=nbins, alpha=.5)\n",
    "plt.hist(proba_pos, bins=nbins, alpha=.5)\n",
    "plt.xlabel('probability')\n",
    "plt.ylabel('count')\n",
    "plt.title(\"Distribution of Probabilities by Class\")\n",
    "plt.legend(['neg', 'pos'])\n",
    "\n",
    "# Plot the boxplots of the pos and neg examples\n",
    "plt.subplot(1,3,3)\n",
    "boxplot = plt.boxplot([proba_neg, proba_pos], patch_artist=True, sym='.')\n",
    "boxplot['boxes'][0].set_facecolor('pink')\n",
    "boxplot['boxes'][1].set_facecolor('lightblue')\n",
    "plt.xticks(ticks=[1, 2], labels=['-', '+'])\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.title(\"Probabilities non-Fraud(-) v. Fraud(+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t08DPxClifqL"
   },
   "source": [
    "## Compare Benchmark to GridSearchCV Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFZe3LBYifqN"
   },
   "outputs": [],
   "source": [
    "tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ca0LL5ioifqN"
   },
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IsFLkrIifqO"
   },
   "outputs": [],
   "source": [
    "# PROVIDED\n",
    "\n",
    "# Predict with the benchmark model on the validation set\n",
    "preds_val_bench = tree_model.predict(Xval)\n",
    "\n",
    "# Predict with the best model on the test set\n",
    "preds_val_best = best_model.predict(Xval)\n",
    "\n",
    "# Obtain prediction probabilities for the benchmark model on val set\n",
    "proba_val_bench = tree_model.predict_proba(Xval)\n",
    "\n",
    "# Obtain prediction probabilities for the best model on test set\n",
    "proba_val_best = best_model.predict_proba(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhqi6u5kifqO"
   },
   "outputs": [],
   "source": [
    "# PROVIDED\n",
    "\n",
    "# Benchmark tree model validation set confusion matrix\n",
    "cmtx_val_bench = confusion_matrix(yval, preds_val_bench)\n",
    "confusion_mtx_colormap(cmtx_val_bench, targetnames, targetnames)\n",
    "\n",
    "# Best tree model test set confusion matrix\n",
    "cmtx_val_best = confusion_matrix(yval, preds_val_best)\n",
    "confusion_mtx_colormap(cmtx_val_best, targetnames, targetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfNQX-YVifqP"
   },
   "outputs": [],
   "source": [
    "# PROVIDED\n",
    "# Curves (i.e. ROC, PRC, etc) use metrics_plots.ks_roc_prc_plot and the \n",
    "# the probabilities for the class label of 1\n",
    "\n",
    "# Benchmark tree validation set performance\n",
    "roc_prc_results_val_bench  = ks_roc_prc_plot(yval, proba_val_bench[:,1])\n",
    "\n",
    "# Best tree model validation set performance\n",
    "roc_prc_results_val_best  = ks_roc_prc_plot(yval, proba_val_best[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSxjXCnOifqP"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "1. Discuss the difference in AUC between your hand-selected model and the best model found by GridSearch\n",
    "\n",
    "__TODO__\n",
    "\n",
    "2. How many different hyper-parameter sets did GridSearch consider?\n",
    "\n",
    "__TODO__\n",
    "\n",
    "3. What was the best set of hyper-parameters according to the GridSearch?\n",
    "\n",
    "__TODO__\n",
    "\n",
    "4. Discuss the difference in PR-AUC between your hand-selected model and the best model found by GridSearch\n",
    "\n",
    "__TODO__\n",
    "\n",
    "5. Examining the learned trees for both models, which features appear to be most important in performing this\n",
    "classification task?\n",
    "\n",
    "__TODO__\n",
    "\n",
    "6. Relative to the validation data set, what is the best probability threshold to use to distinguish positive from negative classes?  Why?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework9_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
