{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOZXXjvHYt1W"
   },
   "source": [
    "NAME:__FULLNAME__  \n",
    "\n",
    "# Homework 3: Classifiers\n",
    "\n",
    "### Objectives\n",
    "Follow the TODOs and read through and understand the provided code.\n",
    "For this assignment you will work with extracting different types of labels,\n",
    "constructing predictive classifier models from these labels, and evaluating \n",
    "the generalized performance of these models. Additionally, it is good practice \n",
    "to have a high level understanding of the data that one is working with.  Upon \n",
    "loading the data, we will display the info and summary statistics, and examine the data head/tail, and whether there are any missing data (flagged as NaNs).\n",
    "\n",
    "This assignment utilizes code examples from the lecture on classifiers\n",
    "\n",
    "* Pipelines\n",
    "* Classification\n",
    "  + Label extraction and construction\n",
    "  + Prediction\n",
    "  + Performance Evaluation\n",
    "  + Utilization of Built-In Cross Validation Tools\n",
    "* Do not save work within the MLP_2022 folder\n",
    "  + create a folder in your home directory for assignments, and copy the templates there  \n",
    "\n",
    "### General References\n",
    "* [Python Built-in Functions](https://docs.python.org/3/library/functions.html)\n",
    "* [Python Data Structures](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "* [Pandas DataFrames](https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_reference_api_pandas.DataFrame.html&d=DwMD-g&c=qKdtBuuu6dQK9MsRUVJ2DPXW6oayO8fu4TfEHS8sGNk&r=9ngmsG8rSmDSS-O0b_V0gP-nN_33Vr52qbY3KXuDY5k&m=mcOOc8D0knaNNmmnTEo_F_WmT4j6_nUSL_yoPmGlLWQ&s=h7hQjqucR7tZyfZXxnoy3iitIr32YlrqiFyPATkW3lw&e=)\n",
    "* [Sci-kit Learn Linear Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "  + [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
    "* [Sci-kit Learn Ensemble Models](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)\n",
    "* [Sci-kit Learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "* [Sci-kit Learn Model Selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "\n",
    "### Hand-In Procedure\n",
    "* Execute all cells so they are showing correct results\n",
    "* Notebook (from Jupyter or Colab):\n",
    "  + Submit this file (.ipynb) to the Gradscope Notebook HW3 dropbox\n",
    "* Note: there is no need to submit a PDF file or to submit directly to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BT0Kfr5UYt1h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as peffects\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mT5bZY3jYt1m",
    "outputId": "9c573ed1-7226-4c15-a0af-a5cbc4df8300"
   },
   "outputs": [],
   "source": [
    "# Execute only if using CoLab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTKaNGagYt1p"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs3BOWeFYt1r",
    "outputId": "6cc50bd8-8c7c-4284-8082-eec44b3cca4b"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Load data from subject k2 for week 05\n",
    "Display info() for the data\n",
    "\n",
    "These are data obtained from a baby on the SIPPC. 3D Position (i.e. kinematic)\n",
    "data are collected at 50 Hz, for the x, y, and z positions in meters, for \n",
    "various joints such as the wrists, elbows, shoulders, etc.\n",
    "\"\"\"\n",
    "# Local file name\n",
    "#fname = '~/datasets/baby1/subject_k2_w05.csv'\n",
    "\n",
    "# File name if using CoLab\n",
    "fname = '/content/drive/MyDrive/MLP_2022/datasets/baby1/subject_k2_w05.csv'\n",
    "baby_data_raw = # TODO\n",
    "#TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "7IZRnYLEYt1v",
    "outputId": "5d7c204c-85f2-4498-af26-8b3759dfcc78"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the first few examples\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "rbARGTaKYt1x",
    "outputId": "f3c32bf6-9f79-43dc-b432-0d8bf3f716bf"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the last few examples\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "huhemliiYt10",
    "outputId": "236bb424-7be7-471d-944e-50c10969aa2c"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Display the summary statistics\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIKK27kOYt12",
    "outputId": "b9987470-6132-4d2d-e085-75dca7f27a7e"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Check the dataframe for any NaNs using pandas methods\n",
    "isna() and any() for a summary of the missing data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNYau_OgYt15"
   },
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAedVGreYt16"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "\"\"\"\n",
    "## Support for identifying kinematic variable columns\n",
    "def get_kinematic_properties(data):\n",
    "    # Regular expression for finding kinematic fields\n",
    "    regx = re.compile(\"_[xyz]$\")\n",
    "\n",
    "    # Find the list of kinematic fields\n",
    "    fields = list(data)\n",
    "    fieldsKin = [x for x in fields if regx.search(x)]\n",
    "    return fieldsKin\n",
    "\n",
    "def position_fields_to_velocity_fields(fields, prefix='d_'):\n",
    "    '''\n",
    "    Given a list of position columns, produce a new list\n",
    "    of columns that include both position and velocity\n",
    "    '''\n",
    "    fields_new = [prefix + x for x in fields]\n",
    "    return fields + fields_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9Kv-9b9Yt18",
    "outputId": "b3a6eac0-6453-4505-95b1-9d2f10693274"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Get the names of the sets of fields for the kinematic features and the \n",
    "velocities\n",
    "\"\"\"\n",
    "fieldsKin = get_kinematic_properties(baby_data_raw)\n",
    "fieldsKinVel = position_fields_to_velocity_fields(fieldsKin)\n",
    "print(fieldsKinVel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCONYPDEYt1-"
   },
   "source": [
    "# Construct Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dPuOm2tYt1_"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "\"\"\"\n",
    "# Pipeline component: select subsets of attributes\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs):\n",
    "        self.attribs = attribs\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribs]\n",
    "\n",
    "# Pipeline component: drop all rows that contain invalid values\n",
    "class DataSampleDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.dropna(how='any')\n",
    "\n",
    "# Pipeline component: Compute derivatives\n",
    "class ComputeDerivative(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs, dt=1.0, prefix='d_'):\n",
    "        self.attribs = attribs\n",
    "        self.dt = dt\n",
    "        self.prefix = prefix\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Compute derivatives\n",
    "        Xout = X.copy()\n",
    "        for field in self.attribs:\n",
    "            # Extract the values for this field\n",
    "            values = Xout[field].values\n",
    "            # Compute the difference between subsequent values\n",
    "            diff = values[1:] - values[0:-1]\n",
    "            # Bring the length to be the same as original data\n",
    "            np.append(diff, 0)\n",
    "            # Name of the new field\n",
    "            name = self.prefix + field\n",
    "            Xout[name] = pd.Series(diff / self.dt)\n",
    "        return Xout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC1z4oBRYt2B"
   },
   "source": [
    "# Construct Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y_Rc4kRYt2C"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Create four pipelines. \n",
    "\n",
    "The first pipeline computes the derivatives of select features\n",
    "within the dataframe and then drops rows containing NaNs.\n",
    "\n",
    "The second pipeline extracts the kinematic and velocity (derivative)\n",
    "features from the dataframe.\n",
    "\n",
    "The third pipeline extracts the time from the dataframe.\n",
    "\n",
    "The fourth pipeline extracts the sippc_action from the dataframe.\n",
    "\"\"\"\n",
    "# Sampling rate: number of seconds between each time sample\n",
    "dt = .02\n",
    "\n",
    "# Initial pre-processing\n",
    "pipe_der_drop = Pipeline([\n",
    "    ('derivative', ComputeDerivative(fieldsKin, dt=dt)),\n",
    "    ('dropper', DataSampleDropper())\n",
    "])\n",
    "\n",
    "# Position, velocity selector\n",
    "pipe_kin_vel = Pipeline([\n",
    "    ('selector', DataFrameSelector(fieldsKinVel))\n",
    "])\n",
    "\n",
    "# Time selector\n",
    "pipe_time = Pipeline([\n",
    "    ('selector', DataFrameSelector(['time']))\n",
    "])\n",
    "\n",
    "# Robot velocity selector\n",
    "pipe_robot_vel = Pipeline([\n",
    "    ('selector', DataFrameSelector(['robot_vel_l', 'robot_vel_r']))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYw9x3avYt2D"
   },
   "source": [
    "## Pre-process and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moWhEQWxYt2E"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Use the pipelines to extract the data with kinematic and velocity features, \n",
    "the time, and the sippc actions.\n",
    "See the lecture on classifers for examples\n",
    "\"\"\"\n",
    "# TODO: use the first pipeline to perform an initial cleaning of the data\n",
    "baby_data_prcd =  # TODO\n",
    "\n",
    "# TODO: Use the result from the first pipeline to get the kinematic and \n",
    "#       velocity features by using the pipe_kin_vel pipeline\n",
    "data_pos_vel = # TODO\n",
    "\n",
    "# TODO: Use the result from the first pipeline to get the time by using\n",
    "#       the pipe_time pipeline\n",
    "data_time = # TODO\n",
    "\n",
    "\n",
    "# TODO: Use the result from the first pipeline to get the robot velocity by using\n",
    "#       the pipe_robot_vel pipeline\n",
    "data_robot_vel = #TODO\n",
    "\n",
    "# PROVIDED: Get the dataframes as numpy arrays\n",
    "inputs_pos_vel = data_pos_vel.values\n",
    "time = data_time.values\n",
    "robot_vel = data_robot_vel.values\n",
    "\n",
    "nsamples =  #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXnKfyMpYt2F"
   },
   "source": [
    "## Examine Robot Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "1crM3hqyYt2G",
    "outputId": "31507397-6d13-4816-d5d3-6fda54faabde"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create a plot that contains both the linear velocity (robot_vel[:,0]) and\n",
    "rotational velocity (robot_vel[:,1]).  The plot should contain appropriate labels\n",
    "\n",
    "Note: units are m/s and rad/s, respectively\n",
    "\"\"\"\n",
    "\n",
    "# TODO\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Fe6xcFdYt2I"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Create labels that correspond to \"fast forward motion\" and\n",
    "\"fast rotational motion\"\n",
    "\n",
    "\"\"\"\n",
    "# Fast forward motion\n",
    "labels_linear = robot_vel[:,0] > 0.0005\n",
    "\n",
    "# Leftward turns\n",
    "labels_rotational = (robot_vel[:,1]) > 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "-d6iuFQbYt2J",
    "outputId": "f2f015f1-c67f-4bbd-efd6-14abfc6e87c9"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Augment the figure you created above to show the two newly-created\n",
    "class labels.  Make sure that the resulting figure is easy to read\n",
    "\"\"\"\n",
    "# TODO\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GFZBuocYt2L"
   },
   "source": [
    "## Classification Using Cross Validation\n",
    "### Linear Velocity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBmsKH0nYt2M"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "LINEAR VELOCITY\n",
    "\n",
    "Create a SGDClassifier with random_state=42, max_iter=1e4, tol=1e-3, and\n",
    "that uses a loss function. Fit the model using the position x, y, z\n",
    "and velocity x, y, z for all limbs as the input features to the model. Use\n",
    "the robot linear velocity labels as the output of the model.\n",
    "\n",
    "Use cross_val_predict() to compute predictions for each sample and their\n",
    "corresponding scores. Use 20 cross validation splits (i.e. cv=20).\n",
    "\n",
    "NOTES:\n",
    "- For older versions of scikit-learn (e.g., what is running in CoLab, use 'log' as the loss function.\n",
    "- For modern veresions of scikiet-learn, use 'log_loss'\n",
    "- Expect that this will take some time to compute\n",
    "\n",
    "\"\"\"\n",
    "# Model input\n",
    "X = inputs_pos_vel\n",
    "# Model output\n",
    "y = labels_linear\n",
    "\n",
    "# TODO: Create and fit the classifer\n",
    "#loss ='loss_log' works for version 1.1 and up. Sklearn in Google Colab is at 1.02. Check version with sklearn.__version__\n",
    "clf =  # TODO\n",
    "clf.fit(X, y)\n",
    "\n",
    "# TODO: use cross_val_predict() to compute the scores by setting the 'method'\n",
    "#       parameter equal to 'decision_function'. Please see the reference \n",
    "#       links above\n",
    "scores = # TODO\n",
    "\n",
    "# TODO: use cross_val_predict() to compute the predicted labels by setting \n",
    "#       the 'method' parameter equal to 'predict'. Please see the reference \n",
    "#       links above\n",
    "preds = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "rJ2DjhpWYt2N",
    "outputId": "76c309bf-1c2a-45a7-a96e-92958e332416"
   },
   "outputs": [],
   "source": [
    "# PROVIDED: Compare the true labels to the predicted labels and the scores\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, y, 'b', label='Targets')\n",
    "plt.plot(time, preds-2, 'r', label='Predictions')\n",
    "plt.plot(time, scores-8, 'g', label='Scores')\n",
    "plt.plot([0, time.max()], [-8, -8], \n",
    "         'k', label='threshold')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIunQRrYYt2O"
   },
   "source": [
    "## Plotting Functions - Performance Results\n",
    "## Linear Velocity\n",
    "* Confusion Matrix Color Map\n",
    "* K.S. Plot\n",
    "* ROC Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk08FNU_Yt2P"
   },
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "\"\"\"\n",
    "# Generate a color map plot for a confusion matrix\n",
    "def confusion_mtx_colormap(mtx, xnames, ynames, cbarlabel=\"\"):\n",
    "    ''' \n",
    "    Generate a figure that plots a colormap of a matrix\n",
    "    PARAMS:\n",
    "        mtx: matrix of values\n",
    "        xnames: list of x tick names\n",
    "        ynames: list of the y tick names\n",
    "        cbarlabel: label for the color bar\n",
    "    RETURNS:\n",
    "        fig, ax: the corresponding handles for the figure and axis\n",
    "    '''\n",
    "    nxvars = mtx.shape[1]\n",
    "    nyvars = mtx.shape[0]\n",
    "    \n",
    "    # create the figure and plot the correlation matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(mtx, cmap='summer')\n",
    "    if not cbarlabel == \"\":\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    # Specify the row and column ticks and labels for the figure\n",
    "    ax.set_xticks(range(nxvars))\n",
    "    ax.set_yticks(range(nyvars))\n",
    "    ax.set_xticklabels(xnames)\n",
    "    ax.set_yticklabels(ynames)\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"Actual Labels\")\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, \n",
    "             ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    lbl = np.array([['TN', 'FP'], ['FN', 'TP']])\n",
    "    for i in range(nyvars):\n",
    "        for j in range(nxvars):\n",
    "            text = ax.text(j, i, \"%s = %.3f\" % (lbl[i,j], mtx[i, j]),\n",
    "                           ha=\"center\", va=\"center\", color=\"k\")\n",
    "            #text.set_path_effects([peffects.withStroke(linewidth=2, \n",
    "            #foreground='w')])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "# Compute the ROC Curve and generate the KS plot\n",
    "def ks_roc_plot(targets, scores, FIGWIDTH=12, FIGHEIGHT=6, FONTSIZE=16):\n",
    "    ''' \n",
    "    Generate a figure that plots the ROC Curve and the distributions of the \n",
    "    TPR and FPR over a set of thresholds\n",
    "    PARAMS:\n",
    "        targets: list of true target labels\n",
    "        scores: list of predicted labels or scores\n",
    "    RETURNS:\n",
    "        fpr: false positive rate\n",
    "        tpr: true positive rate\n",
    "        thresholds: thresholds used for the ROC curve\n",
    "        auc: Area under the ROC Curve\n",
    "        fig, axs: corresponding handles for the figure and axis\n",
    "    '''\n",
    "    fpr, tpr, thresholds = roc_curve(targets, scores)\n",
    "    auc_res = auc(fpr, tpr)\n",
    "\n",
    "    # Generate KS plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(FIGWIDTH,FIGHEIGHT))\n",
    "    axs = ax.ravel()\n",
    "    ax[0].plot(thresholds, tpr, color='b')\n",
    "    ax[0].plot(thresholds, fpr, color='r')\n",
    "    ax[0].plot(thresholds, tpr - fpr, color='g')\n",
    "    ax[0].invert_xaxis()\n",
    "    ax[0].set_xlabel('threshold', fontsize=FONTSIZE)\n",
    "    ax[0].set_ylabel('fraction', fontsize=FONTSIZE)\n",
    "    ax[0].legend(['TPR', 'FPR', 'K-S Distance'], fontsize=FONTSIZE)\n",
    "    \n",
    "    # Generate ROC Curve plot\n",
    "    ax[1].plot(fpr, tpr, color='b')\n",
    "    ax[1].plot([0,1], [0,1], 'r--')\n",
    "    ax[1].set_xlabel('FPR', fontsize=FONTSIZE)\n",
    "    ax[1].set_ylabel('TPR', fontsize=FONTSIZE)\n",
    "    ax[1].set_aspect('equal', 'box')\n",
    "    auc_text = ax[1].text(.05, .95, \"AUC = %.4f\" % auc_res, \n",
    "                          color=\"k\", fontsize=FONTSIZE)\n",
    "    print(\"AUC:\", auc_res)\n",
    "\n",
    "    return fpr, tpr, thresholds, auc_res, fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "fMsCKQ3oYt2R",
    "outputId": "2388bbd8-97dd-45f8-dcb6-002cce4b74f7"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "\n",
    "Compute the confusion matrix using sklearn's confusion_matrix() function and \n",
    "generate a color map using the provided confusion_mtx_colormap() for the model \n",
    "built using the distance labels.\n",
    "\"\"\"\n",
    "label_names = ['slow', 'fast forward']\n",
    "\n",
    "dist_confusion_mtx = # TODO\n",
    "confusion_mtx_colormap( # TODO )\n",
    "\n",
    "nneg = dist_confusion_mtx[0].sum()\n",
    "npos = dist_confusion_mtx[1].sum()\n",
    "npos, nneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "FuqoFcqAYt2S",
    "outputId": "eb0996e8-20c3-4183-dab6-283aeb8e35e2"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot histograms of the scores from the model built using the linear velocity labels.\n",
    "Comparing distribution of scores for positive and negative examples.\n",
    "Create one subplot of the distribution of all the scores. \n",
    "Create a second subplot overlaying the distribution of the scores of the \n",
    "positive examples (i.e. positive here means examples with a label of 1) with \n",
    "the distributionof the negative examples (i.e. negative here means examples \n",
    "with a label of 0). Use 41 as the number of bins.\n",
    "See the lecture on classifiers for examples\n",
    "\"\"\"\n",
    "scores_pos = [scores[idx] for (idx, y_) in enumerate(y) if y_ > 0]\n",
    "scores_neg = [scores[idx] for (idx, y_) in enumerate(y) if y_ == 0]\n",
    "\n",
    "nbins = 41\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "# TODO\n",
    "\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# TODO\n",
    "\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('count')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "LKRTWXxnYt2T",
    "outputId": "145fa28b-ae2e-4aa2-9cbd-49bdc8c93464"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "DISTANCE\n",
    "Use ks_roc_plot() to plot the ROC curve and the KS plot for the model\n",
    "constructed with the linear velocity labels\n",
    "\"\"\"\n",
    "\n",
    "fpr, tpr, thresholds, auc_res, ks_roc_fig, ks_roc_axs = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fMe4dCeYt2U"
   },
   "source": [
    "# Classification Using Cross Validation\n",
    "## Rotational Velocity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HAn5TdzYt2V"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "ROTATIONAL VELOCITY\n",
    "\n",
    "Create a SGDClassifier with random_state=42, max_iter=1e4, tol=1e-3, and\n",
    "that uses a log loss function. Fit the model using the position x, y, z\n",
    "and velocity x, y, z for all limbs as the input features to the model. Use\n",
    "the robot linear velocity labels as the output of the model.\n",
    "\n",
    "Use cross_val_predict() to get predictions for each sample and their\n",
    "cooresponding scores. Use 20 cross validation splits (i.e. cv=20).\n",
    "\n",
    "Plot the true labels, predictions, and the scores.\n",
    "For more information observe the general references above\n",
    "\"\"\"\n",
    "# Model input\n",
    "X = inputs_pos_vel\n",
    "# Model output\n",
    "y = labels_rotational\n",
    "\n",
    "# TODO: Create and fit the classifer\n",
    "clf = #TODO\n",
    "\n",
    "# TODO: use cross_val_predict() to compute the scores by setting the 'method'\n",
    "#       parameter equal to 'decision_function'. Please see the reference \n",
    "#       links above\n",
    "scores = # TODO\n",
    "\n",
    "# TODO: use cross_val_predict() to compute the predicted labels by setting \n",
    "#       the 'method' parameter equal to 'predict'. Please see the reference \n",
    "#       links above\n",
    "preds = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "4ufV-6qwYt2W",
    "outputId": "c655c5ae-22a0-4ca2-8046-467336de1c3f"
   },
   "outputs": [],
   "source": [
    "# PROVIDED: Compare the true labels to the predicted labels and the scores\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, y, 'b', label='Targets')\n",
    "plt.plot(time, preds-2, 'r', label='Predictions')\n",
    "plt.plot(time, scores-8, 'g', label='Scores')\n",
    "plt.plot([0, time.max()], [-8, -8], \n",
    "         'k', label='threshold')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vbAzkgWYt2X"
   },
   "source": [
    "## Plotting Functions - Performance Results\n",
    "Linear Velocity\n",
    "* Confusion Matrix Color Map\n",
    "* K.S. Plot\n",
    "* ROC Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "CzOw50U2Yt2X",
    "outputId": "d0f56869-398b-4a6e-c0eb-f916f6e8cbfa"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "\n",
    "Compute the confusion matrix using sklearn's confusion_matrix() function and \n",
    "generate a color map using the provided confusion_mtx_colormap() for the model \n",
    "built using the distance labels.\n",
    "\"\"\"\n",
    "label_names = ['slow', 'fast forward']\n",
    "\n",
    "dist_confusion_mtx = # TODO\n",
    "confusion_mtx_colormap(# TODO)\n",
    "\n",
    "nneg = dist_confusion_mtx[0].sum()\n",
    "npos = dist_confusion_mtx[1].sum()\n",
    "npos, nneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "XPfdWlMFYt2Z",
    "outputId": "9ebfc848-906e-4597-bf98-efafd2a0a12f"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot histograms of the scores from the model built using the linear velocity labels.\n",
    "Comparing distribution of scores for positive and negative examples.\n",
    "Create one subplot of the distribution of all the scores. \n",
    "Create a second subplot overlaying the distribution of the scores of the \n",
    "positive examples (i.e. positive here means examples with a label of 1) with \n",
    "the distribution of the negative examples (i.e. negative here means examples \n",
    "with a label of 0). Use 41 as the number of bins.\n",
    "See the lecture on classifiers for examples\n",
    "\"\"\"\n",
    "scores_pos = [scores[idx] for (idx, y_) in enumerate(y) if y_ > 0]\n",
    "scores_neg = [scores[idx] for (idx, y_) in enumerate(y) if y_ == 0]\n",
    "\n",
    "nbins = 41\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "# TODO\n",
    "\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# TODO\n",
    "\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('count')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "TPu3mZOtYt2a",
    "outputId": "80d6c5e6-e93a-4bee-dcbc-f4a5026c16fa"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "KS-DISTANCE\n",
    "Use ks_roc_plot() to plot the ROC curve and the KS plot for the model\n",
    "constructed with the linear velocity labels\n",
    "\"\"\"\n",
    "\n",
    "# TODO\n",
    "fpr, tpr, thresholds, auc_res, ks_roc_fig, ks_roc_axs = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHWCl6elYt2b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTgaStIjYt2b"
   },
   "source": [
    "## Reflection\n",
    "Write a short paragraph that compares the results for the two classificaiton problems that you have just solved (specifically, the linear vs rotational labels problems).  How well does each do?  For each, which is the best choice of score threshold?  And, which problem does the SGDClassifier solve better?  Note that you do not need to make a statistical argument at this time.\n",
    "\n",
    "### My answer\n",
    "TODO: paragraph here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmJluw_WYt2d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
