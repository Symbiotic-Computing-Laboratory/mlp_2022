{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Practice\n",
    "## Module 11: Decision Trees\n",
    "## Tree learning demonstration\n",
    "\n",
    "Andrew H. Fagg (andrewhfagg@gmail.com)\n",
    "\n",
    "Important Notes:\n",
    "- This skeleton deviates some from what is presented in video\n",
    "- New: I have added some new cells where we learn/test using the entire data set.  This allows us to see what is possible if we have enough data.\n",
    "- UPDATED: cross_val_predict() overfits the data really easy.  Use cv=40 to cv=100 to have enough data in the training set to produce generalizable models\n",
    "- NOTE: In the video, I suggest that proba[:,0] corresponds to the positive class probabilities.  This is not true.  proba[:,1] are the positive class probabilities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from IPython import display\n",
    "\n",
    "#############################3\n",
    "# Default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drivetorque\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From book\n",
    "# Pipeline component: select subsets of attributes\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs):\n",
    "        self.attribs = attribs\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribs].values\n",
    "\n",
    "# Pipeline component: New transformer class: drop all rows that contain invalid values\n",
    "class DataSampleDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.dropna(how = 'any')\n",
    "\n",
    "# Pipeline component: Compute derivatives\n",
    "class ComputeDerivative(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribs, dt=1.0, prefix='d_'):\n",
    "        self.attribs = attribs\n",
    "        self.dt = dt\n",
    "        self.prefix = prefix\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Compute derivatives\n",
    "        Xout = X.copy()\n",
    "        for field in self.attribs:\n",
    "            # Extract the values for this field\n",
    "            values = Xout[field].values\n",
    "            # Compute the difference between subsequent values\n",
    "            diff = values[1:] - values[0:-1]\n",
    "            # Bring the length to be the same as original data\n",
    "            np.append(diff, 0)\n",
    "            # Name of the new field\n",
    "            name = self.prefix + field\n",
    "            # 20 ms time step\n",
    "            Xout[name] = pd.Series(diff / self.dt)\n",
    "        return Xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Support for identifying kinematic variable columns\n",
    "def get_kinematic_properties(data):\n",
    "    # Regular expression for finding kinematic fields\n",
    "    px = re.compile(\"_[xyz]$\")\n",
    "\n",
    "    # Find the list of kinematic fields\n",
    "    fields = list(data)\n",
    "    fieldsKin = [x for x in fields if px.search(x)]\n",
    "    return fieldsKin\n",
    "\n",
    "def position_fields_to_position_and_velocity_fields(fields, prefix='d_'):\n",
    "    '''\n",
    "    Given a list of position columns, produce a new list\n",
    "    of columns that include both position and velocity\n",
    "    '''\n",
    "    fields_new = [prefix + x for x in fields]\n",
    "    return fields + fields_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you may need to change this path to get to the data\n",
    "#fname = '/home/fagg/datasets/baby1/subject_k2_w10.csv'\n",
    "fname = '/content/drive/MyDrive/MLP_2022/datasets/baby1/subject_k2_w10.csv'\n",
    "\n",
    "# Load the data\n",
    "infant_data = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time / actions\n",
    "time = infant_data['time'].values\n",
    "action = infant_data['sippc_action'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the kinematic variables\n",
    "fieldsKin = get_kinematic_properties(infant_data)\n",
    "fieldsKinVel = position_fields_to_position_and_velocity_fields(fieldsKin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepipe = Pipeline([\n",
    "    ('derivative', ComputeDerivative(fieldsKin, dt=.02)),\n",
    "    ('dropper', DataSampleDropper())\n",
    "])\n",
    "\n",
    "# Position pipe\n",
    "pipe_pos = Pipeline([('selector', DataFrameSelector(fieldsKin))])\n",
    "\n",
    "# Position + velocity selector\n",
    "pipe_pos_vel = Pipeline([('selector', DataFrameSelector(fieldsKinVel))])\n",
    "\n",
    "# Robot action\n",
    "attribs_label = ['sippc_action']\n",
    "pipe_label = Pipeline([('selector', DataFrameSelector(attribs_label))])\n",
    "\n",
    "# Time\n",
    "attribs_time = ['time']\n",
    "pipe_time = Pipeline([('selector', DataFrameSelector(attribs_time))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pipelines \n",
    "infant_data2 = prepipe.fit_transform(infant_data)\n",
    "\n",
    "# Selection\n",
    "inputs_pos = pipe_pos.transform(infant_data2)\n",
    "inputs_pos_vel = pipe_pos_vel.transform(infant_data2)\n",
    "action = pipe_label.transform(infant_data2).reshape((-1,))\n",
    "time = pipe_time.transform(infant_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_motion = action > 0\n",
    "\n",
    "# Action onset (any action)\n",
    "\n",
    "label_assistance_onset_any = (action[0:-1] == 0) & (action[1:] > 0) & (action[1:] <= 8)\n",
    "label_assistance_onset_any = np.append(label_assistance_onset_any, 0)\n",
    "\n",
    "# Action onset: power steering\n",
    "label_assistance_onset_ps = (action[0:-1] == 0) & (action[1:] > 0) & (action[1:] <= 4)\n",
    "label_assistance_onset_ps = np.append(label_assistance_onset_ps, 0)\n",
    "\n",
    "# Action onset: gesture\n",
    "label_assistance_onset_g = (action[0:-1] == 0) & (action[1:] >= 5) & (action[1:] <= 8)\n",
    "label_assistance_onset_g = np.append(label_assistance_onset_g, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data Set\n",
    "Our goal: remove samples that are immediately around positive onset_g events\n",
    "\n",
    "Motivation:\n",
    "- onset_g happens at one sample.  However, the kinematics will be similar for the samples surrounding this event\n",
    "- Fix 1: We will just remove the samples immediately following the event\n",
    "- Fix 2: We will turn the 10 samples prior to the event to positive examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean to tell us whether to keep the samples\n",
    "keep = np.ones(shape=label_assistance_onset_g.shape)\n",
    "events = np.where(label_assistance_onset_g)\n",
    "for e in events[0]:\n",
    "    # Remove samples immediately after the trigger event\n",
    "    keep[e+1:e+26] = 0\n",
    "    # Swich negative class labels before the event to positive\n",
    "    label_assistance_onset_g[e-10:e] = 1\n",
    "\n",
    "# Indices of the original data set to keep\n",
    "indices = np.where(keep > 0)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep a subset of the available data\n",
    "ins = inputs_pos_vel[indices,:]\n",
    "outs = label_assistance_onset_g[indices]\n",
    "time_modified = time[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_leaf_nodes=????, criterion='log_loss') \n",
    "\n",
    "# Class weights can better balance the tree\n",
    "#, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw training experiment\n",
    "Use all data for training / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the one decision tree and evaluate with the same data\n",
    "classifier.fit(ins, outs)\n",
    "prob_a = classifier.predict_proba(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default decision boundary at .5\n",
    "pred_main = prob_a[:,1] >= 0.5\n",
    "\n",
    "# Compute and display the corresponding confusion matrix\n",
    "confusion = confusion_matrix(outs, pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss goes down as complexity of the tree goes up\n",
    "#  NOTE: this is not the case if we are overfitting\n",
    "log_loss(outs, prob_a[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probabilities and true label over time\n",
    "plt.figure()\n",
    "plt.plot(time_modified, ???, 'r')\n",
    "plt.plot(time_modified, ???, 'b')\n",
    "plt.plot(time_modified, outs*.1-.2, 'k')\n",
    "plt.ylabel('probability')\n",
    "plt.xlabel('time (s)')\n",
    "\n",
    "plt.xlim((50,70))\n",
    "plt.legend(['other', 'movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element #1 is the positive prob\n",
    "fpr, tpr, thresholds = roc_curve(outs, prob_a[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(????)\n",
    "ax.plot(????)\n",
    "ax.plot(????)\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('fraction')\n",
    "ax.set_xlim([1,0])\n",
    "ax.legend(['TPR', 'FPR', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fig = plt.figure(figsize=(5,4.5))\n",
    "plt.plot(????)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "#fig.axes[0].set_aspect('equal', 'box')\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation experiment\n",
    "The video will take you through this section.  \n",
    "\n",
    "Remember that proba[:,1] are the true class probabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are badly imbalanced.  Need a lot of cv folds to see a positive result\n",
    "proba = cross_val_predict(???)\n",
    "\n",
    "# Including n_jobs allows parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive label threshold default is 0.5\n",
    "# Display the corresponding confusion matrix\n",
    "pred = proba[:,1] >= \n",
    "\n",
    "confusion = \n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probabilities and true label over time\n",
    "plt.figure()\n",
    "plt.plot(time_modified, ???, 'r')\n",
    "plt.plot(time_modified, ???, 'b')\n",
    "plt.plot(time_modified, outs*.1-.2, 'k')\n",
    "plt.ylabel('probability')\n",
    "plt.xlabel('time (s)')\n",
    "\n",
    "plt.xlim((50,70))\n",
    "plt.legend(['other', 'movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate.  Use proba[:,1]\n",
    "log_loss(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element #1 is the positive prob\n",
    "fpr, tpr, thresholds = roc_curve(????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR / FPR curves\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds, ???, color='b')\n",
    "ax.plot(thresholds, ???, color='r')\n",
    "ax.plot(thresholds, ???, color='g')\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('fraction')\n",
    "ax.set_xlim([1,0])\n",
    "ax.legend(['TPR', 'FPR', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fig = plt.figure(figsize=(5,4.5))\n",
    "plt.plot(????)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "#fig.axes[0].set_aspect('equal', 'box')\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render learned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(classifier, ???) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng -o tree_model.png tree_model.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"tree_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
